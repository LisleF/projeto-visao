{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trabalho.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbBGnDY9-qJ5"
      },
      "source": [
        "#Projeto 1\n",
        "#Objetivo:\n",
        "\n",
        "Expor a ideia e como será estruturado as funcionalidades"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdv0J3BfC0yN"
      },
      "source": [
        "#GLOBAIS\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "\n",
        "#parametros globais\n",
        "train_folder = 'dataset/dataset_updated/training_set/'\n",
        "test_folder = 'dataset/dataset_updated/validation_set/'\n",
        "image_format = '.jpg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0ySMYSiC46V"
      },
      "source": [
        "#AUXILIARES\n",
        "\n",
        "def getFolders(data_base):\n",
        "  data_folders = []\n",
        "  for name in os.listdir(data_base):\n",
        "    if(os.path.isdir(data_base + name)):\n",
        "      data_folders.append(name)\n",
        "  print(data_folders)\n",
        "\n",
        "  return data_folders\n",
        "\n",
        "def load_images(folder):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder,filename))\n",
        "        \n",
        "        #img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "    return images\n",
        "\n",
        "def resize_all_images(images):\n",
        "    width = 0\n",
        "    height =  0\n",
        "    resized_imgs = []\n",
        "    \n",
        "    for im in images:\n",
        "        h, w, d = im.shape\n",
        "        height += h\n",
        "        width += w\n",
        "        \n",
        "    width = int(width/len(images))\n",
        "    height = int(height/len(images))\n",
        "                \n",
        "    for im in images:\n",
        "        resized_imgs.append(cv2.resize(im,(width,height)))\n",
        "    return resized_imgs\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03DS83SK-3xn"
      },
      "source": [
        "#Tarefa 1: Pre-processamento"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLCvJIzD_jC3"
      },
      "source": [
        "def choosePreProcess(im, param):\n",
        "    if (param['pre_process']['method'] == 'Clahe'):\n",
        "        return doClahe(im, param)\n",
        "    elif (param['pre_process']['method'] == 'Eq_Hist'):\n",
        "        return doEqualizazaoHistograma(im, param)\n",
        "    elif (param['pre_process']['method'] == 'Quant_Linear'):\n",
        "        return doQuantizacaoLinear(im,param)\n",
        "    elif (param['pre_process']['method'] == 'Median'):\n",
        "        return doMedian(im,param)\n",
        "    elif (param['pre_process']['method'] == 'Gaussian'):\n",
        "        return doGaussian(im,param)\n",
        "    elif (param['pre_process']['method'] == 'Blur'):\n",
        "        return doBlur(im,param)\n",
        "    elif (param['pre_process']['method'] == 'Bilateral'):\n",
        "        return doBilateral(im,param)\n",
        "    elif (param['pre_process']['method'] == 'BrilhoContraste'):\n",
        "        return doBrilhoContraste(im,param)\n",
        "\n",
        "        \n",
        "def doBlur(im,params):\n",
        "    return cv2.blur(im,(5,5))\n",
        "\n",
        "def doMedian(im, params):\n",
        "    return cv2.medianBlur(im,5)\n",
        "\n",
        "def doGaussian(im, params):\n",
        "    return cv2.GaussianBlur(im,(5,5),0)\n",
        "\n",
        "def doBilateral(im, params):\n",
        "    return cv2.bilateralFilter(im,9,75,75)\n",
        "\n",
        "def doClahe(im, params):\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0,tileGridSize=(7,7))\n",
        "    hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n",
        "    hsv[:,:,2] = clahe.apply(hsv[:,:,2])\n",
        "    rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
        "    return im\n",
        "\n",
        "def doEqualizazaoHistograma(im, params):\n",
        "    hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n",
        "    hsv[:,:,2] = cv2.equalizeHist(hsv[:,:,2])\n",
        "    rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
        "    \n",
        "    return rgb \n",
        "\n",
        "def doQuantizacaoLinear(im, params):\n",
        "    \n",
        "    (h,w) = im.shape[:2]\n",
        "    \n",
        "    im = cv2.cvtColor(im, cv2.COLOR_BGR2LAB)\n",
        "    \n",
        "    im = im.reshape((im.shape[0] * im.shape[1],3))\n",
        "    \n",
        "    clt = MiniBatchKMeans(n_clusters = params['K_Value'])\n",
        "    labels = clt.fit_predict(im)\n",
        "    quant = clt.cluster_centers_.astype(\"uint8\")[labels]\n",
        "    \n",
        "    quant = quant.reshape((h,w,3))\n",
        "    quant = cv2.cvtColor(quant,cv2.COLOR_LAB2BGR)\n",
        "    \n",
        "    '''im2 = im.flatten()\n",
        "    im2 = np.transpose(im2)\n",
        "    im2= np.float32(im2)\n",
        "    k = params['K_Value']\n",
        "    criterio = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "    compactness, labels, centers = cv2.kmeans(im2,k,None,criterio,10, cv2.KMEANS_PP_CENTERS)\n",
        "\n",
        "    centers = np.uint8(centers)\n",
        "    res = centers[labels.flatten()]\n",
        "    im_quant = res.reshape((im.shape))'''\n",
        "    return quant\n",
        "\n",
        "def doBrilhoContraste(im, params):\n",
        "    \n",
        "    if params['brilho'] != 0:\n",
        "        if params['brilho'] > 0:\n",
        "            s = params['brilho']\n",
        "            highlight = 255\n",
        "        else:\n",
        "            s = 0\n",
        "            highlight = 255 + params['brilho']\n",
        "        alpha_b = (highlight - s)/255\n",
        "        gamma_b = s\n",
        "        \n",
        "        buf = cv2.addWeighted(im, alpha_b, im, 0, gamma_b)\n",
        "    else:\n",
        "        buf = im.copy()\n",
        "    \n",
        "    if params['contraste'] != 0:\n",
        "        f = 131*(params['contraste'] + 127)/(127*(131-params['contraste']))\n",
        "        alpha_c = f\n",
        "        gamma_c = 127*(1-f)\n",
        "        \n",
        "        buf = cv2.addWeighted(buf, alpha_c, buf, 0, gamma_c)\n",
        "\n",
        "    return buf\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "IiR5fdZY-bG2",
        "outputId": "af7e317a-8288-4f0c-cde6-e7d8b8d088c5"
      },
      "source": [
        "#TESTE\n",
        "images = load_images('dataset/dataset_updated/training_set/teste/')\n",
        "images = resize_all_images(images)\n",
        "\n",
        "\n",
        "params_teste = {\n",
        "    'pre_process':'Gaussian',\n",
        "    'K_Value' : 10,\n",
        "    'brilho': 64,\n",
        "    'contraste' : 64\n",
        "    \n",
        "}\n",
        "\n",
        "images_pre_processed = []\n",
        "for image in images:\n",
        "    images_pre_processed.append(choosePreProcess(image,params_teste))\n",
        "    \n",
        "cv2.imshow(\"test\", images_pre_processed[0])\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "string indices must be integers",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-36-3dede12d872a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mimages_pre_processed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mimages_pre_processed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchoosePreProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparams_teste\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages_pre_processed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-35-08a2f620d63e>\u001b[0m in \u001b[0;36mchoosePreProcess\u001b[1;34m(im, param)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mchoosePreProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pre_process'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'method'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Clahe'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdoClahe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pre_process'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'method'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Eq_Hist'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdoEqualizazaoHistograma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaFYKCMc_F6h"
      },
      "source": [
        "#Tarefa 2: Extração de Característica "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNOFqxcWEcx-"
      },
      "source": [
        "from skimage.feature import local_binary_pattern\n",
        "import cv2\n",
        "\n",
        "def chooseFeats(im, params):\n",
        "    if params[\"feat\"] == \"lbp\":\n",
        "        return doLBP(im, params)\n",
        "    elif params[\"feat\"] == \"color_hist\":\n",
        "        return doColorHistogram(im, params)\n",
        "    elif params[\"feat\"] == \"glcm\":\n",
        "        return doGLCM(im, params)\n",
        "\n",
        "\n",
        "def doLBP(im, params):\n",
        "    lbp = local_binary_pattern(im, params[\"n_points\"], params[\"radius\"], params[\"methods\"])\n",
        "    hist = cv2.calcHist([lbp], [0, None, [256], [0, 256]])\n",
        "    return hist.ravel()\n",
        "\n",
        "def doColorHistogram(im, params):\n",
        "\n",
        "    if params['color_space'] == 'LAB':\n",
        "        im = cv2.cvtColor(im, cv2.COLOR_RGB2LAB)\n",
        "    elif params['color_space'] == 'YCrCb':\n",
        "        im = cv2.cvtColor(im, cv2.COLOR_RGB2YCrCb)\n",
        "    elif params['color_space'] == 'HSV':\n",
        "        im = cv2.cvtColor(im, cv2.COLOR_RGB2HSV)\n",
        "    elif params['color_space'] == 'RGB':\n",
        "        pass\n",
        "        \n",
        "    channels = cv2.split(im)\n",
        "    hist = []\n",
        "\n",
        "    for channel in channels:\n",
        "        channel_hist = cv2.calcHist([channel],[0],None,[256],[0,256])\n",
        "        hist.extend(channel_hist)\n",
        "\n",
        "    return np.array(hist).ravel()\n",
        "\n",
        "def doGLCM(im, params):\n",
        "    glcm = greycomatrix(im, params[\"distances\"], params[\"angles\"])\n",
        "    features = [\n",
        "        greycoprops(glcm, \"contrast\"),\n",
        "        greycoprops(glcm, \"dissimilarity\"),\n",
        "        greycoprops(glcm, \"homogeneity\"),\n",
        "        greycoprops(glcm, \"energy\"),\n",
        "        greycoprops(glcm, \"correlation\"),\n",
        "        greycoprops(glcm, \"ASM\")\n",
        "    ]\n",
        "\n",
        "    return np.array(features).ravel()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4bH8MDREZiO"
      },
      "source": [
        "#Executa em conjunto as duas primeiras etapas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kEHmGMKGKMp",
        "outputId": "7bf70ebd-e012-4eec-ad7c-4a2c35358b9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def getPreProcessAndExtractFeatures(path_folder, params):\n",
        "\tclasses_folders = getFolders(path_folder)\n",
        "\n",
        "\tdata = []\n",
        "\tlabels = []\n",
        "\tfor f in classes_folders:\n",
        "\t\tdataset = glob.glob(path_folder + f + \"/*\" + image_format)\n",
        "\t\tfor arq in dataset:\n",
        "\t\t\tim = cv2.imread(arq)\t\t\t\n",
        "\t\t\n",
        "\t\t\tim = choosePreProcess(im, params)\n",
        "\t\t\tfeats = chooseFeats(im, params)\n",
        "\n",
        "\t\t\tdata.append(feats)\n",
        "\t\t\tlabels.append(f)\n",
        "\treturn np.asarray(data), np.asarray(labels)\n",
        "\n",
        "X_base, y_base = getBase()\t\n",
        "print(X_base.shape)\n",
        "print(y_base.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['2', '1', '0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9BCvqH7_K7H"
      },
      "source": [
        "#Tarefa 3: Seleção de Característica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yk1vGvDFJLF"
      },
      "source": [
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "#nesse ponto, a base já deve ter passado pela etapa 1 e etapa 2\n",
        "def chooseBestFeats(params):\n",
        "  if (param['selection'] == 'rfe')\n",
        "    doRFE()\n",
        "\n",
        "def evalBestFeats():\n",
        "  #1. faz treinamento com validação cruzada  \n",
        "  #2. retorna o valor do score\n",
        "\n",
        "#problema aqui: o pre-processamento deve ser aplicado a toda a base\n",
        "#mas, até escolher o melhor, ele não deve aplicar as alterações\n",
        "#ou seja, a base original deve permanecer inalterada\n",
        "def doRFE():\n",
        "  parametros = dict(estimator=[ ... ],\n",
        "                    step=[ ...],\n",
        "                    min_features_to_select=[ ...] )\n",
        "  \n",
        "  lr = LogisticRegression(random_state=42, solver='liblinear')\n",
        "  rfecv = RFECV(estimator=lr, \n",
        "              step=1, \n",
        "              cv=5,\n",
        "              min_features_to_select = 100,\n",
        "              scoring='accuracy')\n",
        "  rfecv.fit(X_train, y_train)\n",
        "\n",
        "  #Se vamos usar o do sklearn: precisamos criar o estimator que substitui a função eval\n",
        "  #Podemos fazer o nosso, passando por parâmetro a função eval e o dicionário de parâmetros\n",
        "  #RandomSearch ... ?\n",
        "  #GridSearch   ... ?\n",
        "\n",
        "  #onde está sendo avaliado \n",
        "  #na forma de grid\n",
        "  for  ...\n",
        "    for ...\n",
        "      evalBestFeats()\n",
        "\n",
        "\n",
        "  #deve retornar a os vetores de caracteristicas filtrados pela técnica com os melhores parâmetros aplicados"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYrM7V_k_OaX"
      },
      "source": [
        "#Tarefa 4: Seleção de classificador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX6r3SApHmFb"
      },
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, KFold, RandomizedSearchCV\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, cohen_kappa_score, confusion_matrix\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import os, glob\n",
        "\n",
        "from joblib import dump, load\n",
        "\n",
        "\n",
        "def report_best_scores(results, n_top=3):\n",
        "    for i in range(1, n_top + 1):\n",
        "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
        "        for candidate in candidates:\n",
        "            print(\"Model with rank: {0}\".format(i))\n",
        "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
        "                  results['mean_test_score'][candidate],\n",
        "                  results['std_test_score'][candidate]))\n",
        "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
        "            print(\"\")\n",
        "\n",
        "#nesse ponto, a base já deve ter passado pela etapa 1, etapa 2 e etapa 3\n",
        "def chooseBestClassifier(params):\n",
        "  if (params['classifier'] == 'randomforest'):\n",
        "    doRandomForest()\n",
        "\n",
        "\n",
        "class XGBoost_Classifier:\n",
        "    \n",
        "    def __init__(self, qtd_classes, best_scores):\n",
        "        self.num_class = qtd_classes\n",
        "        self.best_scores = best_scores\n",
        "    \n",
        "    def search_model(self, X, y, grid, steps):        \n",
        "        xgb_model = xgb.XGBClassifier(objective='multi:softprob', random_state=42)\n",
        "        \n",
        "        search = RandomizedSearchCV(xgb_model, param_distributions=grid, random_state=42, n_iter=200, cv=3, verbose=1, n_jobs=1, return_train_score=True)\n",
        "\n",
        "        search.fit(X, y)\n",
        "        \n",
        "        self.best_scores(search.cv_results_, 1)\n",
        "    \n",
        "    def train_single(self, X_train, Y_train, X_test, Y_test, params, steps):\n",
        "        model = xgb.train(param, D_train, steps)\n",
        "        preds = model.predict(D_test)\n",
        "        preds = np.asarray([np.argmax(line) for line in preds])\n",
        "        acc = accuracy_score(Y_test, preds)\n",
        "        kpp = cohen_kappa_score(Y_test, preds)\n",
        "        print(\"Accuracy = {}\".format(acc))\n",
        "        print(\"Precision = {}\".format(precision_score(Y_test, preds, average='macro')))\n",
        "        print(\"Recall = {}\".format(recall_score(Y_test, preds, average='macro')))\n",
        "        print(\"Kappa = {}\".format(kpp))\n",
        "        \n",
        "class SVM_Classifier:\n",
        "    \n",
        "    def __init__(self, best_scores):\n",
        "        self.best_scores = best_scores\n",
        "    \n",
        "    def search_model(self, X, y, grid):        \n",
        "        svc = SVC(probability=True)\n",
        "        \n",
        "        search = RandomizedSearchCV(svc, param_distributions=grid, random_state=42, n_iter=2, cv=3, verbose=3, n_jobs=1, return_train_score=True)\n",
        "        \n",
        "        search.fit(X, y)\n",
        "        \n",
        "        self.best_scores(search.cv_results_, 1)\n",
        "    \n",
        "    def train_single(self, X_train, Y_train, X_test, Y_test, params):\n",
        "        svc = SVC(probability=True)\n",
        "        svc.set_params(params)\n",
        "        \n",
        "        model = svc.fit(X_train, Y_train)\n",
        "        y_predicted = model.predict(X_test)\n",
        "        \n",
        "        acc = sk.metrics.accuracy_score(Y_test, y_predicted)\n",
        "        prec = sk.metrics.precision_score(Y_test, y_predicted, average=None)[1]\n",
        "        rec = sk.metrics.recall_score(Y_test, y_predicted, average=None)[1]\n",
        "        kpp = sk.metrics.cohen_kappa_score(Y_test, y_predicted)\n",
        "        print(\"Accuracy: {:.1%}\".format(acc))\n",
        "        print(\"Precision: {:.1%}\".format(prec))\n",
        "        print(\"Recall: {:.1%}\".format(rec))\n",
        "        print(\"Kappa: {:.1%}\".format(kpp))\n",
        "\n",
        "class KNN_Classifier:\n",
        "    \n",
        "    def __init__(self, best_scores):\n",
        "        self.best_scores = best_scores\n",
        "    \n",
        "    def search_model(self, X, y, grid):        \n",
        "        knn = KNeighborsClassifier()\n",
        "        \n",
        "        search = RandomizedSearchCV(knn, param_distributions=grid, random_state=42, n_iter=200, cv=3, verbose=1, n_jobs=1, return_train_score=True)\n",
        "        \n",
        "        search.fit(X, y)\n",
        "        \n",
        "        self.best_scores(search.cv_results_, 1)\n",
        "    \n",
        "    def train_single(self, X_train, Y_train, X_test, Y_test, params):\n",
        "        knn = KNeighborsClassifier()\n",
        "        knn.set_params(params)\n",
        "        \n",
        "        model = knn.fit(X_train, Y_train)\n",
        "        y_predicted = model.predict(X_test)\n",
        "        \n",
        "        acc = sk.metrics.accuracy_score(Y_test, y_predicted)\n",
        "        prec = sk.metrics.precision_score(Y_test, y_predicted, average=None)[1]\n",
        "        rec = sk.metrics.recall_score(Y_test, y_predicted, average=None)[1]\n",
        "        kpp = sk.metrics.cohen_kappa_score(Y_test, y_predicted)\n",
        "        print(\"Accuracy: {:.1%}\".format(acc))\n",
        "        print(\"Precision: {:.1%}\".format(prec))\n",
        "        print(\"Recall: {:.1%}\".format(rec))\n",
        "        print(\"Kappa: {:.1%}\".format(kpp))\n",
        "        \n",
        "class RandomForest_Classifier:\n",
        "    \n",
        "    def __init__(self, best_scores):\n",
        "        self.best_scores = best_scores\n",
        "    \n",
        "    def search_model(self, X, y, grid):        \n",
        "        rfc = RandomForestClassifier()\n",
        "        \n",
        "        search = RandomizedSearchCV(rfc, param_distributions=grid, random_state=42, n_iter=200, cv=3, verbose=1, n_jobs=1, return_train_score=True)\n",
        "        \n",
        "        search.fit(X, y)\n",
        "        \n",
        "        self.best_scores(search.cv_results_, 1)\n",
        "    \n",
        "    def train_single(self, X_train, Y_train, X_test, Y_test, params):\n",
        "        rfc = RandomForestClassifier()\n",
        "        rfc.set_params(params)\n",
        "        \n",
        "        model = rfc.fit(X_train, Y_train)\n",
        "        y_predicted = model.predict(X_test)\n",
        "        \n",
        "        acc = sk.metrics.accuracy_score(Y_test, y_predicted)\n",
        "        prec = sk.metrics.precision_score(Y_test, y_predicted, average=None)[1]\n",
        "        rec = sk.metrics.recall_score(Y_test, y_predicted, average=None)[1]\n",
        "        kpp = sk.metrics.cohen_kappa_score(Y_test, y_predicted)\n",
        "        print(\"Accuracy: {:.1%}\".format(acc))\n",
        "        print(\"Precision: {:.1%}\".format(prec))\n",
        "        print(\"Recall: {:.1%}\".format(rec))\n",
        "        print(\"Kappa: {:.1%}\".format(kpp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if6L7r_1_QnX"
      },
      "source": [
        "#Em comum: otimizador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvOIGFS7-bOr"
      },
      "source": [
        "BASE_PATH_TRAIN = \"dataset/dataset_updated/training_set/\"\n",
        "BASE_PATH_VALIDATION = \"dataset/dataset_updated/validation_set\"\n",
        "\n",
        "def load_database(path: str, params: dict):\n",
        "    labels = []\n",
        "\n",
        "    folders = os.listdir(path)\n",
        "    labels = folders\n",
        "    \n",
        "    features = []\n",
        "    labels = []\n",
        "    error_images = []\n",
        "    max_size = 0\n",
        "    for f in folders:\n",
        "        images = glob.glob(path + f + \"/*.*\")    \n",
        "        for img in images:\n",
        "            image = cv2.imread(img)\n",
        "\n",
        "            if image is not None:\n",
        "                width = 224\n",
        "                height = 224\n",
        "                #resized = resized_image(image, width, height) #TODO: fazer o zero padding e deixar ela do tamanho desejado\n",
        "                \n",
        "                image = choosePreProcess(image, params) #escolhendo o pré-processamento\n",
        "                #feature = chooseFeats(image, params) #escolhendo a extração de caracteristicas\n",
        "\n",
        "                #features.append(feature)\n",
        "                labels.append(folders.index(f))\n",
        "            else:\n",
        "                error_images.append(img)\n",
        "    \n",
        "    features = np.array(features)\n",
        "    labels = np.array(labels)\n",
        "    \n",
        "    return features, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCsP1nXp_SaU",
        "outputId": "ee07bf9f-d86c-43a3-a1c0-361d10c162da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
        "from hyperopt import hp\n",
        "import random\n",
        "\n",
        "param_space ={\n",
        "    'pre_process' : hp.choice('preprocess',[\n",
        "        {\n",
        "            'method': 'Clahe'\n",
        "        },\n",
        "        {\n",
        "            'method' : 'Eq_Hist'\n",
        "        },\n",
        "        {\n",
        "            'method' : 'Quant_Linear',\n",
        "            'K_Value' : hp.choice('K_Value',[8,16,32,64])\n",
        "        },\n",
        "        {\n",
        "            'method' : 'Median'\n",
        "        },\n",
        "        {\n",
        "            'method' : 'Gaussian'\n",
        "        },\n",
        "        {\n",
        "            'method' : 'Blur'\n",
        "        },\n",
        "        {\n",
        "            'method' : 'Bilateral'\n",
        "        },\n",
        "        {\n",
        "            'method' : 'BrilhoContrate',\n",
        "            'brilho' : hp.choice('brilho',[0,32,64,127]),\n",
        "            'contraste' : hp.choice('contraste',[0,32,64,127])\n",
        "        }\n",
        "    ]),\n",
        "    'feature_extractor' : hp.choice('feature_extractor',[\n",
        "        {\n",
        "            'method' : 'lbp',\n",
        "            'n_points': hp.choice('n_points', range(2, 9)),\n",
        "            'radius': hp.choice('radius', range(2, 9)),\n",
        "            'method': hp.choice('method', ['default', 'ror'. 'uniform', 'nri_uniform', 'var']),\n",
        "         \n",
        "        },\n",
        "        {\n",
        "            'method' : 'glcm',\n",
        "            'distance': hp.choice('distance', range(2, 9)),\n",
        "            'angles': hp.choice('angles', [0, np.pi/4, np.pi/3, np.pi/2, (3*np.pi)/4])\n",
        "        },\n",
        "        {\n",
        "            'method': 'color_hist',\n",
        "            'color_space': hp.choice('color_space', ['LAB', 'YCrCb', 'HSV', 'RGB'])\n",
        "        }\n",
        "    ])\n",
        "    }\n",
        "\n",
        "def acc_model(params):\n",
        "    print (params)\n",
        "    return random.uniform(0.8, 1.0)\n",
        "\n",
        "def hyperopt_fitness(params: dict):\n",
        "    print(params)\n",
        "    features_train, labels_train = load_database(BASE_PATH_TRAIN, params)\n",
        "    features_test, labels_test = load_database(BASE_PATH_VALIDATION, params)\n",
        "    \n",
        "    '''scaler = StandardScaler()\n",
        "    scaler.fit(features_train)\n",
        "    \n",
        "    features_train = scaler.transform(features_train)\n",
        "    features_test = scaler.transform(features_test)\n",
        "    \n",
        "    selector_model = chooseFeaturesSelection(features_train, labels_train, params)\n",
        "    selector_model.transform(features_train)\n",
        "    selector_model.transform(features_test)\n",
        "        \n",
        "    classifier, classifier_params = chooseBestClassifier(features_selected, labels, params)\n",
        "    scores = classifier.train_single(features_train, labels_train, features_test, labels_test, classifier_params)'''\n",
        "    return 0.85\n",
        "\n",
        "trials = Trials()\n",
        "best = fmin(hyperopt_fitness, \n",
        "            param_space, \n",
        "            algo=tpe.suggest, \n",
        "            max_evals=10, \n",
        "            trials=trials)\n",
        "\n",
        "#Predict\n",
        "#..."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'feature_extractor': {'method': 'methodname1', 'params ..': '...'}, 'pre_process': {'brilho': 0, 'contraste': 0, 'method': 'BrilhoContrate'}}\n",
            "{'feature_extractor': {'method': 'methodname1', 'params ..': '...'}, 'pre_process': {'method': 'Bilateral'}}           \n",
            "{'feature_extractor': {'method': 'methodname2', 'params ..': '...'}, 'pre_process': {'method': 'Clahe'}}               \n",
            " 20%|████████████▍                                                 | 2/10 [04:47<17:25, 130.63s/trial, best loss: 0.85]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMuO-M2h-bQk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
