{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbBGnDY9-qJ5"
   },
   "source": [
    "#Projeto 1\n",
    "#Objetivo:\n",
    "\n",
    "Expor a ideia e como será estruturado as funcionalidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "hdv0J3BfC0yN"
   },
   "outputs": [],
   "source": [
    "#GLOBAIS\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "#parametros globais\n",
    "train_folder = 'dataset/dataset_updated/training_set/'\n",
    "test_folder = 'dataset/dataset_updated/validation_set/'\n",
    "image_format = '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "n0ySMYSiC46V"
   },
   "outputs": [],
   "source": [
    "#AUXILIARES\n",
    "\n",
    "def getFolders(data_base):\n",
    "  data_folders = []\n",
    "  for name in os.listdir(data_base):\n",
    "    if(os.path.isdir(data_base + name)):\n",
    "      data_folders.append(name)\n",
    "  print(data_folders)\n",
    "\n",
    "  return data_folders\n",
    "\n",
    "def load_images(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        \n",
    "        #img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "def resize_all_images(images):\n",
    "    width = 0\n",
    "    height =  0\n",
    "    resized_imgs = []\n",
    "    \n",
    "    for im in images:\n",
    "        h, w, d = im.shape\n",
    "        height += h\n",
    "        width += w\n",
    "        \n",
    "    width = int(width/len(images))\n",
    "    height = int(height/len(images))\n",
    "                \n",
    "    for im in images:\n",
    "        resized_imgs.append(cv2.resize(im,(width,height)))\n",
    "    return resized_imgs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "03DS83SK-3xn"
   },
   "outputs": [],
   "source": [
    "#Tarefa 1: Pre-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "kLCvJIzD_jC3"
   },
   "outputs": [],
   "source": [
    "def choosePreProcess(im, param):\n",
    "    if (param['pre_process'] == 'Clahe'):\n",
    "        return doClahe(im, param)\n",
    "    elif (param['pre_process'] == 'Eq_Hist'):\n",
    "        return doEqualizazaoHistograma(im, param)\n",
    "    elif (param['pre_process'] == 'Quant_Linear'):\n",
    "        return doQuantizacaoLinear(im,param)\n",
    "    elif (param['pre_process'] == 'Median'):\n",
    "        return doMedian(im,param)\n",
    "    elif (param['pre_process'] == 'Gaussian'):\n",
    "        return doGaussian(im,param)\n",
    "    elif (param['pre_process'] == 'Blur'):\n",
    "        return doBlur(im,param)\n",
    "    elif (param['pre_process'] == 'Bilateral'):\n",
    "        return doBilateral(im,param)\n",
    "    elif (param['pre_process'] == 'BrilhoContraste'):\n",
    "        return doBrilhoContraste(im,param)\n",
    "\n",
    "        \n",
    "def doBlur(im,params):\n",
    "    return cv2.blur(im,(5,5))\n",
    "\n",
    "def doMedian(im, params):\n",
    "    return cv2.medianBlur(im,5)\n",
    "\n",
    "def doGaussian(im, params):\n",
    "    return cv2.GaussianBlur(im,(5,5),0)\n",
    "\n",
    "def doBilateral(im, params):\n",
    "    return cv2.bilateralFilter(im,9,75,75)\n",
    "\n",
    "def doClahe(im, params):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0,tileGridSize=(7,7))\n",
    "    hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n",
    "    hsv[:,:,2] = clahe.apply(hsv[:,:,2])\n",
    "    rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "    return im\n",
    "\n",
    "def doEqualizazaoHistograma(im, params):\n",
    "    hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n",
    "    hsv[:,:,2] = cv2.equalizeHist(hsv[:,:,2])\n",
    "    rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    return rgb \n",
    "\n",
    "def doQuantizacaoLinear(im, params):\n",
    "    \n",
    "    (h,w) = im.shape[:2]\n",
    "    \n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2LAB)\n",
    "    \n",
    "    im = im.reshape((image.shape[0] * image.shape[1],3))\n",
    "    \n",
    "    clt = MiniBatchKMeans(n_clusters = params['K_Value'])\n",
    "    labels = clt.fit_predict(im)\n",
    "    quant = clt.cluster_centers_.astype(\"uint8\")[labels]\n",
    "    \n",
    "    quant = quant.reshape((h,w,3))\n",
    "    quant = cv2.cvtColor(quant,cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    '''im2 = im.flatten()\n",
    "    im2 = np.transpose(im2)\n",
    "    im2= np.float32(im2)\n",
    "    k = params['K_Value']\n",
    "    criterio = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    compactness, labels, centers = cv2.kmeans(im2,k,None,criterio,10, cv2.KMEANS_PP_CENTERS)\n",
    "\n",
    "    centers = np.uint8(centers)\n",
    "    res = centers[labels.flatten()]\n",
    "    im_quant = res.reshape((im.shape))'''\n",
    "    return quant\n",
    "\n",
    "def doBrilhoContraste(im, params):\n",
    "    \n",
    "    if params['brilho'] != 0:\n",
    "        if params['brilho'] > 0:\n",
    "            s = params['brilho']\n",
    "            highlight = 255\n",
    "        else:\n",
    "            s = 0\n",
    "            highlight = 255 + params['brilho']\n",
    "        alpha_b = (highlight - s)/255\n",
    "        gamma_b = s\n",
    "        \n",
    "        buf = cv2.addWeighted(im, alpha_b, im, 0, gamma_b)\n",
    "    else:\n",
    "        buf = im.copy()\n",
    "    \n",
    "    if params['contraste'] != 0:\n",
    "        f = 131*(params['contraste'] + 127)/(127*(131-params['contraste']))\n",
    "        alpha_c = f\n",
    "        gamma_c = 127*(1-f)\n",
    "        \n",
    "        buf = cv2.addWeighted(buf, alpha_c, buf, 0, gamma_c)\n",
    "\n",
    "    return buf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TESTE\n",
    "images = load_images('dataset/dataset_updated/training_set/teste/')\n",
    "images = resize_all_images(images)\n",
    "\n",
    "\n",
    "params_teste = {\n",
    "    'pre_process':'BrilhoContraste',\n",
    "    'K_Value' : 10,\n",
    "    'brilho': 64,\n",
    "    'contraste' : 64\n",
    "    \n",
    "}\n",
    "images_pre_processed = []\n",
    "for image in images:\n",
    "    images_pre_processed.append(choosePreProcess(image,params_teste))\n",
    "    \n",
    "cv2.imshow(\"test\", images_pre_processed[0])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "DaFYKCMc_F6h"
   },
   "outputs": [],
   "source": [
    "#Tarefa 2: Extração de Característica "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LNOFqxcWEcx-"
   },
   "outputs": [],
   "source": [
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "#nesse ponto, a base já deve ter passado pela etapa 1\n",
    "def chooseFeats(im, params):\n",
    "  if (param['feats'] == 'LBP')\n",
    "    return doLBP(im, params)\n",
    "\n",
    "\n",
    "def doLBP(im, params):\n",
    "  \n",
    "  lbp = local_binary_pattern(im, n_points, radius, METHOD)\n",
    "  (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, 255))\n",
    "  hist = hist.astype(\"float\")\n",
    "  hist /= (hist.sum())\n",
    "\n",
    "  return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4bH8MDREZiO"
   },
   "source": [
    "#Executa em conjunto as duas primeiras etapas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "6kEHmGMKGKMp",
    "outputId": "7bf70ebd-e012-4eec-ad7c-4a2c35358b9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '1', '0']\n"
     ]
    }
   ],
   "source": [
    "def getPreProcessAndExtractFeatures(path_folder, params):\n",
    "\tclasses_folders = getFolders(path_folder)\n",
    "\n",
    "\tdata = []\n",
    "\tlabels = []\n",
    "\tfor f in classes_folders:\n",
    "\t\tdataset = glob.glob(path_folder + f + \"/*\" + image_format)\n",
    "\t\tfor arq in dataset:\n",
    "\t\t\tim = cv2.imread(arq)\t\t\t\n",
    "\t\t\n",
    "\t\t\tim = choosePreProcess(im, params)\n",
    "\t\t\tfeats = chooseFeats(im, params)\n",
    "\n",
    "\t\t\tdata.append(feats)\n",
    "\t\t\tlabels.append(f)\n",
    "\treturn np.asarray(data), np.asarray(labels)\n",
    "\n",
    "X_base, y_base = getBase()\t\n",
    "print(X_base.shape)\n",
    "print(y_base.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9BCvqH7_K7H"
   },
   "source": [
    "#Tarefa 3: Seleção de Característica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3yk1vGvDFJLF"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "#nesse ponto, a base já deve ter passado pela etapa 1 e etapa 2\n",
    "def chooseBestFeats(params):\n",
    "  if (param['selection'] == 'rfe')\n",
    "    doRFE()\n",
    "\n",
    "def evalBestFeats():\n",
    "  #1. faz treinamento com validação cruzada  \n",
    "  #2. retorna o valor do score\n",
    "\n",
    "#problema aqui: o pre-processamento deve ser aplicado a toda a base\n",
    "#mas, até escolher o melhor, ele não deve aplicar as alterações\n",
    "#ou seja, a base original deve permanecer inalterada\n",
    "def doRFE():\n",
    "  parametros = dict(estimator=[ ... ],\n",
    "                    step=[ ...],\n",
    "                    min_features_to_select=[ ...] )\n",
    "  \n",
    "  lr = LogisticRegression(random_state=42, solver='liblinear')\n",
    "  rfecv = RFECV(estimator=lr, \n",
    "              step=1, \n",
    "              cv=5,\n",
    "              min_features_to_select = 100,\n",
    "              scoring='accuracy')\n",
    "  rfecv.fit(X_train, y_train)\n",
    "\n",
    "  #Se vamos usar o do sklearn: precisamos criar o estimator que substitui a função eval\n",
    "  #Podemos fazer o nosso, passando por parâmetro a função eval e o dicionário de parâmetros\n",
    "  #RandomSearch ... ?\n",
    "  #GridSearch   ... ?\n",
    "\n",
    "  #onde está sendo avaliado \n",
    "  #na forma de grid\n",
    "  for  ...\n",
    "    for ...\n",
    "      evalBestFeats()\n",
    "\n",
    "\n",
    "  #deve retornar a os vetores de caracteristicas filtrados pela técnica com os melhores parâmetros aplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYrM7V_k_OaX"
   },
   "source": [
    "#Tarefa 4: Seleção de classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UX6r3SApHmFb"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "#nesse ponto, a base já deve ter passado pela etapa 1, etapa 2 e etapa 3\n",
    "def chooseBestClassifier(params):\n",
    "  if (param['classifier'] == 'randomforest')\n",
    "    doRandomForest()\n",
    "\n",
    "\n",
    "def doRandomForest():\n",
    "\n",
    "  #direto da doc\n",
    "  # Number of trees in random forest\n",
    "  n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "  # Number of features to consider at every split\n",
    "  max_features = ['auto', 'sqrt']\n",
    "  # Maximum number of levels in tree\n",
    "  max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "  max_depth.append(None)\n",
    "  # Minimum number of samples required to split a node\n",
    "  min_samples_split = [2, 5, 10]\n",
    "  # Minimum number of samples required at each leaf node\n",
    "  min_samples_leaf = [1, 2, 4]\n",
    "  # Method of selecting samples for training each tree\n",
    "  bootstrap = [True, False]\n",
    "  # Create the random grid\n",
    "  random_grid = {'n_estimators': n_estimators,\n",
    "                'max_features': max_features,\n",
    "                'max_depth': max_depth,\n",
    "                'min_samples_split': min_samples_split,\n",
    "                'min_samples_leaf': min_samples_leaf,\n",
    "                'bootstrap': bootstrap}\n",
    "\n",
    "  rf = RandomForestClassifier()\n",
    "  rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "  rf_random.fit(train_features, train_labels)  \n",
    "\n",
    "  ...\n",
    "\n",
    "  #realiza o experimento e devolve as métricas\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "if6L7r_1_QnX"
   },
   "source": [
    "#Em comum: otimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "YCsP1nXp_SaU",
    "outputId": "ee07bf9f-d86c-43a3-a1c0-361d10c162da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 6.0, 'type': 'dtree'}\n",
      "{'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 3.0, 'type': 'dtree'}\n",
      "{'C': 0.3860507163883026, 'kernel': {'ktype': 'linear'}, 'type': 'svm'}\n",
      "{'C': 7.611796230284283, 'kernel': {'ktype': 'linear'}, 'type': 'svm'}\n",
      "{'type': 'naive_bayes'}\n",
      "{'type': 'naive_bayes'}\n",
      "{'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 9.0, 'type': 'dtree'}\n",
      "{'C': 2.127415403926089, 'kernel': {'ktype': 'linear'}, 'type': 'svm'}\n",
      "{'C': 0.7091905442547609, 'kernel': {'ktype': 'RBF', 'width': 0.5511719314784943}, 'type': 'svm'}\n",
      "{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 3.0, 'type': 'dtree'}\n",
      "100%|██████████| 10/10 [00:00<00:00, 51.44it/s, best loss: -0.987312099434029]\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt import hp\n",
    "import random\n",
    "\n",
    "param_space = hp.choice('classifier_type', [\n",
    "    {\n",
    "        'type': 'naive_bayes',\n",
    "    },\n",
    "    {\n",
    "        'type': 'svm',\n",
    "        'C': hp.lognormal('svm_C', 0, 1),\n",
    "        'kernel': hp.choice('svm_kernel', [\n",
    "            {'ktype': 'linear'},\n",
    "            {'ktype': 'RBF', 'width': hp.lognormal('svm_rbf_width', 0, 1)},\n",
    "            ]),\n",
    "    },\n",
    "    {\n",
    "        'type': 'dtree',\n",
    "        'criterion': hp.choice('dtree_criterion', ['gini', 'entropy']),\n",
    "        'max_depth': hp.choice('dtree_max_depth',\n",
    "            [None, hp.qlognormal('dtree_max_depth_int', 3, 1, 1)]),\n",
    "        'min_samples_split': hp.qlognormal('dtree_min_samples_split', 2, 1, 1),\n",
    "    },\n",
    "    ])\n",
    "\n",
    "\n",
    "def acc_model(params):\n",
    "    print (params)\n",
    "    return random.uniform(0.8, 1.0)\n",
    "\n",
    "def fitness(params):\n",
    "    acc = acc_model(params)\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fitness, \n",
    "            param_space, \n",
    "            algo=tpe.suggest, \n",
    "            max_evals=10, \n",
    "            trials=trials)\n",
    "\n",
    "#Predict\n",
    "#..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Ideia_para_trabalho.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
